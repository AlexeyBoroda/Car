{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обновление библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T16:48:35.669404Z",
     "iopub.status.busy": "2024-10-13T16:48:35.669404Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install phik\n",
    "!pip install shap\n",
    "!pip install lightgbm\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "from warnings import simplefilter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from phik import phik_matrix\n",
    "from phik.report import plot_correlation_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler, RobustScaler \n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVR  # Вместо SVC используем SVR\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML #Используется для прорисовки координат SHAP\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots  # Исправленный импорт\n",
    "from sklearn.feature_selection import SelectKBest, f_classif \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Константы\n",
    "RANDOM_STATE = 42\n",
    "line_1 = '-'*125 #линия \n",
    "line_2 = '_'*125#линия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задача №1\n",
    "#Выделем дискретные и непрерывные количественныз переменные\n",
    "discrete_columns =['employment_years', 'supervisor_evaluation']\n",
    "continuous_columns = ['job_satisfaction_rate', 'salary']\n",
    "\n",
    "#Категориальные переменные \n",
    "categorical_features = ['dept','level','workload','last_year_promo','last_year_violations']\n",
    "\n",
    "#Задача №2                        \n",
    "#Выделем дискретные и непрерывные количественныз переменные\n",
    "quit_discrete_columns = ['employment_years','supervisor_evaluation','quit']\n",
    "quit_continuous_columns = ['salary']\n",
    "#Категориальные переменные \n",
    "quit_categorical_features = ['dept','level','workload','workload','last_year_violations','last_year_promo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция об общей информации о датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(data):\n",
    "    \"\"\"\n",
    "    Функция выводит основную информацию о датасете: первые 5 строк, общую информацию, основные статистики,\n",
    "    количество явных дубликатов и количество пропусков\n",
    "\n",
    "    Args:\n",
    "        data(pandas.DataFrame): Датасет \n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    display(data.head())\n",
    "    display(data.info())\n",
    "    display(data.describe().T)\n",
    "    print('Кол-во явных дубликатов:', data.duplicated().sum())\n",
    "    print('Кол-во пропусков:\\n', data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция для анализа количественных переменных в разбивке на дискретные и непрерывные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Функция для анализа количественных переменных в разбивке на дискретные и непрерывные\n",
    "\n",
    "def plot_histograms_for_df(df, name, discrete_columns, continuous_columns):\n",
    "    \"\"\"\n",
    "    Функция для построения графиков для всех указанных дискретных и непрерывных столбцов в датафрейме.\n",
    "    Дискретные признаки визуализируются с помощью countplot, а непрерывные - с помощью histplot с линиями среднего и медианы.\n",
    "    \n",
    "    Параметры:\n",
    "    - df: DataFrame с данными.\n",
    "    - name: Строка, которая будет добавлена к заголовку каждого подграфика.\n",
    "    - discrete_columns: Список названий дискретных признаков.\n",
    "    - continuous_columns: Список названий непрерывных признаков.\n",
    "    \"\"\"\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Определяем все столбцы для визуализации\n",
    "    columns = discrete_columns + continuous_columns\n",
    "\n",
    "    # Определяем количество строк и столбцов для подграфиков\n",
    "    n_cols = 2  # Количество столбцов подграфиков\n",
    "    n_rows = (len(columns) + n_cols - 1) // n_cols  # Количество строк подграфиков\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten()  # Преобразуем в 1D массив для удобной итерации\n",
    "\n",
    "    for ax, column in zip(axes, columns):\n",
    "        if column in discrete_columns:\n",
    "            # Дискретные признаки\n",
    "            sns.countplot(x=column, data=df, ax=ax)\n",
    "            ax.set_title(f'{name} - {column} (дискретный)', fontsize=12)\n",
    "            ax.set_xlabel(column, fontsize=10)\n",
    "            ax.set_ylabel('Частота', fontsize=10)\n",
    "        elif column in continuous_columns:\n",
    "            # Непрерывные признаки\n",
    "            sns.histplot(data=df, x=column, bins=20, kde=True, ax=ax)\n",
    "            ax.set_title(f'{name} - {column} (непрерывный)', fontsize=12)\n",
    "            ax.set_xlabel(column, fontsize=10)\n",
    "            ax.set_ylabel('Частота', fontsize=10)\n",
    "\n",
    "            # Добавляем медиану и среднее значение\n",
    "            median_value = df[column].median()\n",
    "            mean_value = df[column].mean()\n",
    "            ax.axvline(median_value, color='r', linestyle='--', label=f'Медиана: {median_value:.2f}')\n",
    "            ax.axvline(mean_value, color='g', linestyle='-', label=f'Среднее: {mean_value:.2f}')\n",
    "            ax.legend(fontsize=8)\n",
    "\n",
    "    # Удаляем лишние подграфики, если они есть\n",
    "    total_plots = n_rows * n_cols\n",
    "    if len(columns) < total_plots:\n",
    "        for ax in axes[len(columns):]:\n",
    "            fig.delaxes(ax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\"\"\" \n",
    "# Пример вызова функции:\n",
    "discrete_columns = ['колонка1', 'колонка2']\n",
    "continuous_columns = ['колонка3', 'колонка4']\n",
    "plot_histograms_for_df(df, 'Данные', discrete_columns, continuous_columns)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция визулизации выбросов для непрерывных и дискретных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция визулизации выбросов для непрерывных и дискретных данных\n",
    "\n",
    "def plot_interactive_plots(df, name, continuous_columns, discrete_columns):\n",
    "    \"\"\"\n",
    "    Функция для построения интерактивных графиков:\n",
    "    - boxplot для непрерывных признаков\n",
    "    - countplot для дискретных признаков\n",
    "\n",
    "    Параметры:\n",
    "    - df: DataFrame с данными.\n",
    "    - name: Строка, которая будет добавлена к заголовку каждого подграфика.\n",
    "    - continuous_columns: Список названий непрерывных признаков. Если None, используются все числовые признаки из DataFrame.\n",
    "    - discrete_columns: Список названий дискретных признаков. Если None, используются все дискретные (нечисловые) признаки из DataFrame.\n",
    "    \n",
    "    Описание:\n",
    "    Функция строит интерактивные boxplot для непрерывных признаков и countplot для дискретных признаков.\n",
    "    Если каких-либо признаков нет, то графики для них не строятся.\n",
    "    \"\"\"\n",
    "\n",
    "    # Удаляем столбец 'id', если он присутствует в данных\n",
    "    df_copy = df.drop(columns='id', errors='ignore')\n",
    "\n",
    "    # Если не указаны списки признаков, по умолчанию все числовые признаки считаются непрерывными, а остальные — дискретными\n",
    "    if continuous_columns is None:\n",
    "        continuous_columns = df_copy.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    if discrete_columns is None:\n",
    "        discrete_columns = df_copy.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    # Определяем количество графиков для непрерывных и дискретных признаков\n",
    "    n_continuous = len(continuous_columns)\n",
    "    n_discrete = len(discrete_columns)\n",
    "    \n",
    "    total_plots = n_continuous + n_discrete\n",
    "    \n",
    "    # Если нет признаков для построения, выводим сообщение\n",
    "    if total_plots == 0:\n",
    "        print(\"Нет признаков для построения графиков\")\n",
    "        return\n",
    "\n",
    "    # Создаем сетку подграфиков, исходя из общего числа графиков\n",
    "    fig = make_subplots(rows=(total_plots + 1) // 2, cols=2, subplot_titles=[f\"{name} - {col}\" for col in continuous_columns + discrete_columns])\n",
    "\n",
    "    # Построение boxplot для непрерывных признаков\n",
    "    row, col = 1, 1\n",
    "    for column in continuous_columns:\n",
    "        boxplot = px.box(df_copy, y=column).data[0]\n",
    "        fig.add_trace(boxplot, row=row, col=col)\n",
    "        \n",
    "        # Переход на следующую колонку/строку\n",
    "        if col == 1:\n",
    "            col = 2\n",
    "        else:\n",
    "            col = 1\n",
    "            row += 1\n",
    "\n",
    "    # Построение countplot для дискретных признаков\n",
    "    for column in discrete_columns:\n",
    "        countplot = px.histogram(df_copy, x=column).data[0]\n",
    "        fig.add_trace(countplot, row=row, col=col)\n",
    "        \n",
    "        # Переход на следующую колонку/строку\n",
    "        if col == 1:\n",
    "            col = 2\n",
    "        else:\n",
    "            col = 1\n",
    "            row += 1\n",
    "\n",
    "    # Настройка размера и заголовка\n",
    "    fig.update_layout(\n",
    "        height=300 * ((total_plots + 1) // 2),  # Высота графиков динамически изменяется в зависимости от количества графиков\n",
    "        width=1000,  # Ширина полотна\n",
    "        title_text=f'Interactive Plots of Features for {name}'  # Общий заголовок графиков\n",
    "    )\n",
    "\n",
    "    # Отображение графиков\n",
    "    fig.show()\n",
    "\n",
    "\"\"\"\n",
    "# Пример вызова функции\n",
    "discrete_columns = ['колонка1', 'колонка2']\n",
    "continuous_columns = ['колонка3', 'колонка4']\n",
    "plot_interactive_plots(df, 'Данные', continuous_columns, discrete_columns)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция визулизации категориальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_features(df, name, categorical_features):\n",
    "    \"\"\"\n",
    "    Функция для построения круговых диаграмм для категориальных признаков.\n",
    "\n",
    "    Параметры:\n",
    "    - df: DataFrame с данными.\n",
    "    - categorical_features: Список категориальных признаков, которые необходимо визуализировать.\n",
    "    - name: Строка, которая будет добавлена к заголовку каждого подграфика.\n",
    "\n",
    "    Описание:\n",
    "    Строит круговые диаграммы для категориальных признаков, используя сетку графиков.\n",
    "    \"\"\"\n",
    "    # Подсчитываем общее количество категориальных признаков\n",
    "    total_plots = len(categorical_features)\n",
    "\n",
    "    # Задаем количество строк и столбцов для подграфиков, исходя из количества категориальных признаков\n",
    "    rows = (total_plots + 1) // 2\n",
    "    fig, axes = plt.subplots(rows, 2, figsize=(15, 5 * rows))  # Изменяем высоту сетки, чтобы учесть количество графиков\n",
    "    axes = axes.ravel()  # Преобразуем 2D массив осей в 1D, чтобы легче было итерироваться\n",
    "\n",
    "    plot_index = 0  # Индекс для выбора текущей оси\n",
    "\n",
    "    # Итерация по каждому категориальному признаку\n",
    "    for column in categorical_features:\n",
    "        if column in df.columns:  # Проверяем, что колонка существует в DataFrame\n",
    "            df[column].value_counts().plot.pie(\n",
    "                ax=axes[plot_index], autopct='%1.1f%%', startangle=90, fontsize=12\n",
    "            )\n",
    "            axes[plot_index].set_title(f'{name} - {column}', fontsize=16)  # Добавляем name к заголовку\n",
    "            axes[plot_index].set_ylabel('')  # Убираем метку оси Y\n",
    "            plot_index += 1\n",
    "\n",
    "    # Удаляем лишние оси, если они есть\n",
    "    if plot_index < len(axes):\n",
    "        for ax in axes[plot_index:]:\n",
    "            fig.delaxes(ax)\n",
    "\n",
    "    # Настраиваем внешний вид диаграмм\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "# Пример использования:\n",
    "categorical_features = ['Category1', 'Category2', 'Category3']\n",
    "plot_categorical_features(df,'Данные',categorical_features)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция для корреляционного анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_correlation_analysis(df, discrete_columns, continuous_columns):\n",
    "    \"\"\"\n",
    "    Функция для выполнения корреляционного анализа с использованием библиотеки phik\n",
    "    и построения тепловой карты для всех данных.\n",
    "\n",
    "    Аргументы:\n",
    "    - df: DataFrame с данными.\n",
    "    - discrete_columns: Список дискретных признаков.\n",
    "    - continuous_columns: Список непрерывных признаков.\n",
    "\n",
    "    Пример использования:\n",
    "    --------------------\n",
    "    # Пример списков с дискретными и непрерывными признаками\n",
    "    discrete_columns = ['dept', 'level', 'workload']\n",
    "    continuous_columns = ['salary', 'age', 'working_hours']\n",
    "\n",
    "    # Вызов функции для выполнения корреляционного анализа\n",
    "    perform_correlation_analysis(df, discrete_columns, continuous_columns)\n",
    "    \"\"\"\n",
    "\n",
    "    # Удаляем столбец 'id', так как он не нужен для анализа\n",
    "    df_clean = df.drop('id', axis=1, errors='ignore')\n",
    "\n",
    "    # Построение общей корреляционной матрицы для всех данных\n",
    "    print(\"\\nОбщая корреляционная матрица:\")\n",
    "    corr_matrix = df_clean.phik_matrix(interval_cols=continuous_columns).round(2)\n",
    "\n",
    "    # Отображение общей тепловой карты\n",
    "    plot_correlation_matrix(\n",
    "        corr_matrix.values,\n",
    "        x_labels=corr_matrix.columns,\n",
    "        y_labels=corr_matrix.index,\n",
    "        vmin=0, vmax=1, color_map='Greens',\n",
    "        title=r'Корреляция $\\phi_K$',\n",
    "        fontsize_factor=1.5,\n",
    "        figsize=(20, 15)\n",
    "    )\n",
    "\n",
    "def plot_correlation_matrix(corr_matrix, x_labels, y_labels, vmin, vmax, color_map, title, fontsize_factor, figsize):\n",
    "    \"\"\"\n",
    "    Вспомогательная функция для построения тепловой карты корреляций.\n",
    "\n",
    "    Аргументы:\n",
    "    - corr_matrix: Матрица корреляций.\n",
    "    - x_labels: Метки по оси X.\n",
    "    - y_labels: Метки по оси Y.\n",
    "    - vmin, vmax: Минимальное и максимальное значение корреляции.\n",
    "    - color_map: Цветовая схема.\n",
    "    - title: Заголовок графика.\n",
    "    - fontsize_factor: Фактор увеличения шрифтов.\n",
    "    - figsize: Размер графика.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=color_map, vmin=vmin, vmax=vmax, xticklabels=x_labels, yticklabels=y_labels)\n",
    "    plt.title(title, fontsize=fontsize_factor * 10)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=fontsize_factor * 8)\n",
    "    plt.yticks(fontsize=fontsize_factor * 8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    Пример использования:\n",
    "    --------------------\n",
    "    # Пример списков с дискретными и непрерывными признаками\n",
    "    discrete_columns = ['dept', 'level', 'workload']\n",
    "    continuous_columns = ['salary', 'age', 'working_hours']\n",
    "\n",
    "    # Вызов функции для выполнения корреляционного анализа\n",
    "    perform_correlation_analysis(df, discrete_columns, continuous_columns) \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция для построения графиков зависимости увольнения от признаков в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quit_analysis_in_columns(data, target='quit', plot_type='box', cols=2):\n",
    "    \"\"\"\n",
    "    Функция для автоматического построения графиков зависимости между категориальными и числовыми признаками\n",
    "    с учётом целевого признака (например, увольнения) и выводом графиков в две колонки.\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    data: DataFrame\n",
    "        Датасет для анализа (например, quit_X_train).\n",
    "    \n",
    "    target: str, optional\n",
    "        Целевой признак для анализа (по умолчанию 'quit').\n",
    "\n",
    "    plot_type: str, optional\n",
    "        Тип графика ('box', 'violin'). Зависит от типа данных.\n",
    "\n",
    "    cols: int, optional\n",
    "        Количество колонок для отображения графиков (по умолчанию 2).\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    None\n",
    "        Построит и покажет графики для всех категориальных признаков с числовыми.\n",
    "    \"\"\"\n",
    "    # Получаем список всех категориальных и числовых признаков\n",
    "    categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Убираем целевой признак из списков\n",
    "    if target in categorical_columns:\n",
    "        categorical_columns.remove(target)\n",
    "    if target in numerical_columns:\n",
    "        numerical_columns.remove(target)\n",
    "\n",
    "    # Инициализация для многоколоночного вывода\n",
    "    total_plots = len(categorical_columns) * len(numerical_columns)\n",
    "    rows = (total_plots + cols - 1) // cols  # Определение количества строк для всех графиков\n",
    "    \n",
    "    # Создаем подграфики\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    axes = axes.flatten()  # Преобразуем в плоский массив для удобства работы с осями\n",
    "\n",
    "    plot_index = 0  # Счетчик для отслеживания номера графика\n",
    "\n",
    "    # Проходим по каждому категориальному и числовому признаку и строим графики\n",
    "    for cat_col in categorical_columns:\n",
    "        for num_col in numerical_columns:\n",
    "            plt.sca(axes[plot_index])  # Переключаемся на конкретный подграфик\n",
    "            \n",
    "            if plot_type == 'box':\n",
    "                sns.boxplot(x=cat_col, y=num_col, hue=target, data=data, ax=axes[plot_index])\n",
    "            elif plot_type == 'violin':\n",
    "                sns.violinplot(x=cat_col, y=num_col, hue=target, data=data, split=True, ax=axes[plot_index])\n",
    "            else:\n",
    "                raise ValueError(\"Неверный тип графика. Доступны: 'box', 'violin'\")\n",
    "            \n",
    "            # Устанавливаем заголовок для графика\n",
    "            axes[plot_index].set_title(f'{num_col} по {cat_col} с учётом {target}')\n",
    "            plot_index += 1\n",
    "\n",
    "    # Удаляем пустые подграфики, если общее количество графиков меньше, чем количество подграфиков\n",
    "    for i in range(plot_index, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 1: предсказание уровня удовлетворённости сотрудника"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1.1. Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем датасеты для первой задачи\n",
    "try:\n",
    "    job_X_train = pd.read_csv('datasets/train_job_satisfaction_rate.csv')\n",
    "    job_X_test = pd.read_csv('datasets/test_features.csv')\n",
    "    job_y_test = pd.read_csv('datasets/test_target_job_satisfaction_rate.csv')\n",
    "\n",
    "except:\n",
    "    job_X_train = pd.read_csv('https://code.s3.yandex.net/datasets/train_job_satisfaction_rate.csv')\n",
    "    job_X_test = pd.read_csv('https://code.s3.yandex.net/datasets/test_features.csv')\n",
    "    job_y_test = pd.read_csv('https://code.s3.yandex.net/datasets/test_target_job_satisfaction_rate.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Общая информация о датасетах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `job_X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info(job_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `job_X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info(job_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `job_y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info(job_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий вывод по датасетам **job_X_train**, **job_X_test** и **job_y_test**:\n",
    "\n",
    "1. **job_X_train** (Тренировочная выборка для предсказания уровня удовлетворённости):\n",
    "- **Размер**: 4000 записей и 10 столбцов.\n",
    "- **Признаки**:\n",
    "  - Категориальные: **dept**, **level**, **workload**, **last_year_promo**, **last_year_violations**.\n",
    "  - Числовые: **id**, **employment_years**, **supervisor_evaluation**, **salary**, **job_satisfaction_rate** (целевой признак).\n",
    "- **Пропуски**: Есть пропуски в признаках **dept** (отдел) и **level** (уровень должности).\n",
    "- **Целевой признак**: **job_satisfaction_rate** — уровень удовлетворённости сотрудника.\n",
    "\n",
    "2. **job_X_test** (Тестовая выборка с признаками):\n",
    "- **Размер**: 2000 записей и 9 столбцов (без целевого признака).\n",
    "- **Признаки**:\n",
    "  - Категориальные: **dept**, **level**, **workload**, **last_year_promo**, **last_year_violations**.\n",
    "  - Числовые: **id**, **employment_years**, **supervisor_evaluation**, **salary**.\n",
    "- **Пропуски**: Есть пропуски в колонках **dept** и **level**.\n",
    "- **Целевой признак отсутствует**, так как это тестовая выборка для модели, которая будет предсказывать **job_satisfaction_rate**.\n",
    "\n",
    "3. **job_y_test** (Целевой признак тестовой выборки):\n",
    "- **Размер**: 2000 записей и 2 столбца (**id** и **job_satisfaction_rate**).\n",
    "- **Пропуски отсутствуют**: Все данные целевого признака присутствуют и могут быть использованы для оценки модели.\n",
    "\n",
    "**Общий вывод:**\n",
    "- **Пропуски**: Пропуски имеются в категориальных признаках **dept** и **level** как в тренировочной, так и в тестовой выборке. Их нужно будет обработать на этапе предобработки данных.\n",
    "- **Целевой признак**: Целевой признак **job_satisfaction_rate** присутствует в тренировочной выборке и тестовом наборе меток (**job_y_test**), что позволяет использовать его для обучения моделей и оценки их точности.\n",
    "- **Разнородность данных**: Датасеты содержат как числовые, так и категориальные признаки, поэтому потребуется кодирование категориальных признаков перед обучением модели.\n",
    "- **Целостность данных**: За исключением небольших пропусков в категориальных признаках, данные в хорошем состоянии для дальнейшей работы, включая анализ и построение моделей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1.2. Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пайп замены пропущенных значений на часто частое используемое (strategy='most_frequent')\n",
    "# imputer_pipe = Pipeline(\n",
    "    # [\n",
    "        # (\n",
    "#             'SimpleImputer',\n",
    "#             SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "#         ),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `job_X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выявление неявных дубликатов. Создадим словарь с уникальными значениями для каждого категориального признака\n",
    "unique_values_dict = {col: job_X_train[col].unique().tolist() for col in job_X_train.columns if job_X_train[col].dtype == 'object'}\n",
    "unique_values_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "1. ошибка в слове 'sinior'\n",
    "2. Пропуски (NaN) присутствуют в колонках dept и level   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Повторное исправление опечатки в колонке level\n",
    "job_X_train['level'] = job_X_train['level'].replace('sinior', 'senior')\n",
    "\n",
    "# Проверим уникальные значения в колонке 'level' после исправления\n",
    "job_X_train['level'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применим пайплайн к этим двум столбцам\n",
    "# job_X_train[['dept', 'level']] = imputer_pipe.fit_transform(job_X_train[['dept', 'level']])\n",
    "\n",
    "# Проверим, что пропуски были обработаны\n",
    "# job_X_train[['dept', 'level']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `job_X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выявление неявных дубликатов. Создадим словарь с уникальными значениями для каждого категориального признака\n",
    "unique_values_dict = {col: job_X_test[col].unique().tolist() for col in job_X_test.columns if job_X_test[col].dtype == 'object'}\n",
    "unique_values_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видими пустые ячейки в 'dept','workload' в виде '' и 'level' - nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Исправляем ошибку\n",
    "job_X_test['level'].replace({'sinior': 'senior'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменим \"пустое\" значение `dept` и `workload` на NaN\n",
    "job_X_test['dept'].replace({' ': np.nan}, inplace=True)\n",
    "job_X_test['workload'].replace({' ': np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработаем пропущенные значения при помощи пайплайна \n",
    "# job_X_test[['dept','level']] = imputer_pipe.transform(job_X_test[['dept','level']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Отдельно проработаем workload\n",
    "# job_X_train[['workload']] = imputer_pipe.fit_transform(job_X_train[['workload']])\n",
    "# job_X_test[['workload']] = imputer_pipe.transform(job_X_test[['workload']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Проверка\n",
    "display(job_X_test[job_X_test['dept'].isnull() | job_X_test['level'].isnull() | job_X_test['workload'].isnull()])\n",
    "print(f'Количество пропущенных значений после замены: \\n {job_X_test.isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `job_y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_y_test['job_satisfaction_rate'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы по предобраьотке:\n",
    "\n",
    "**`job_X_train`**\n",
    "- Исправили*sinior -> senior* в столбце `level`\n",
    "- Заменили пропуски при помощи пайплайна (`SimpleImputer`)\n",
    "\n",
    "**`job_X_test`**\n",
    "- Исправили *sinior -> senior* в столбце `level`\n",
    "- Заменили пустые значения (\" \")\n",
    "- Заменили пропуски ари помощи пайплайна (`SimpleImputer`)\n",
    "\n",
    "\n",
    "**`job_y_test`**\n",
    "- Без изменений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1.3. Исследовательский анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Количественные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Гистограммы\n",
    "plot_histograms_for_df(job_X_train,'Данные', discrete_columns, continuous_columns)\n",
    "\n",
    "#Выбросы\n",
    "plot_interactive_plots(job_X_train,'Данные', discrete_columns, continuous_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Категориальные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_features(job_X_train,'Данные', categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Я ревьюер простой: вижу графики признаков - пишу зелёный комментарий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корреляционный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_correlation_analysis(job_X_train, discrete_columns, continuous_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Красивый ковёр задаёт стиль всей работе! (с) Джеффри Лебовски\n",
    "\n",
    "Говоря по-ревьюерски, молодец, что не забыл про корреляционный анализ :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы EDA\n",
    "\n",
    "1. **Распределение признаков**\n",
    "\n",
    "*Дискретные признаки:*\n",
    "- **Отдел (dept)**: Больше всего сотрудников работает в отделе продаж (38%), за ним следует отдел технологий (21.6%) и закупок (15.3%). Наименьшее количество сотрудников в HR (11.4%) и маркетинге (13.8%).\n",
    "- **Уровень должности (level)**: Основная часть сотрудников имеет уровень junior (47.5%), затем идут сотрудники среднего уровня (middle) — 43.6%, и наименьшая часть — старшие сотрудники (senior), составляющие 9%.\n",
    "- **Загруженность (workload)**: Большинство сотрудников имеют среднюю загруженность (51.6%), при этом загруженность на низком уровне у 30% сотрудников, и только 18.4% сотрудников имеют высокую загруженность.\n",
    "- **Повышение за последний год (last_year_promo)**: Лишь 3% сотрудников получили повышение за последний год, что указывает на редкость данного события.\n",
    "- **Нарушения за последний год (last_year_violations)**: 86% сотрудников не нарушали трудовой договор, и только 14% имели нарушения.\n",
    "- **Оценка руководителя (supervisor_evaluation)**: Большинство сотрудников (около 45%) получили оценку \"4\" от руководителя, затем идут сотрудники с оценкой \"3\". Оценки \"5\" и \"1\" встречаются реже.\n",
    "\n",
    "*Непрерывные признаки:*\n",
    "- **Длительность работы (employment_years)**: Наиболее распространённый срок работы сотрудников — 1–2 года. Меньшее количество сотрудников имеет длительный срок работы более 6 лет.\n",
    "- **Зарплата (salary)**: Средняя зарплата составляет около 33,927 условных единиц. Большая часть сотрудников зарабатывает в диапазоне 20,000–40,000. Видны признаки положительной асимметрии — зарплаты выше 60,000 встречаются реже.\n",
    "- **Уровень удовлетворённости (job_satisfaction_rate)**: Удовлетворённость сотрудников варьируется от низкого до высокого уровня. Средняя удовлетворённость составляет около 0.53, медиана — 0.56, что говорит о том, что распределение близко к симметричному, с небольшой положительной асимметрией.\n",
    "\n",
    "2. **Корреляционный анализ**\n",
    "На тепловой карте корреляций видно следующие ключевые моменты:\n",
    "- **Значимая корреляция между уровнем должности (level) и зарплатой (salary)**: Коэффициент корреляции составляет 0.72, что указывает на сильную положительную связь — чем выше уровень должности, тем выше зарплата.\n",
    "- **Корреляция между уровнем должности и длительностью работы (employment_years)**: Коэффициент корреляции составляет 0.68, что логично — сотрудники с более высоким уровнем должности, как правило, дольше работают в компании.\n",
    "- **Корреляция между уровнем должности и загруженностью (workload)**: Коэффициент 0.42 указывает на умеренную корреляцию — с повышением должности, увеличивается и уровень загруженности.\n",
    "- **Оценка руководителя и уровень удовлетворённости**: Видна высокая положительная корреляция (0.76) между оценкой руководителя и уровнем удовлетворённости сотрудника, что указывает на важную роль положительной обратной связи для мотивации сотрудников.\n",
    "\n",
    "**Заключение:**\n",
    "\n",
    "- **Основные факторы, влияющие на уровень удовлетворённости**: Среди факторов, оказывающих влияние на уровень удовлетворённости сотрудников, особенно выделяются оценка руководителя, зарплата и длительность работы в компании.\n",
    "- **Уровень должности играет важную роль**: Зависимость между уровнем должности и удовлетворённостью работы тесно связана с другими факторами, такими как зарплата, загруженность и длительность работы.\n",
    "- **Редкость повышения и нарушения**: Лишь небольшое количество сотрудников нарушают трудовой договор и получают повышение за последний год, что может быть связано с внутренней политикой компании.\n",
    "\n",
    "**Рекомендации:**\n",
    "- Провести дополнительные исследования факторов, влияющих на удовлетворённость, возможно, с применением машинного обучения для предсказания уровня удовлетворённости.\n",
    "- Проанализировать влияние редкости повышения и возможные пути увеличения мотивации через развитие карьерных возможностей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1.4. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предподгатовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовку признаков выполните в пайплайне, дополнив пайплайн шага предобработки.\n",
    "# При кодировании учитывайте особенности признаков и моделей\n",
    "#  и используйте как минимум два кодировщика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим размерность\n",
    "# Оптимизированная проверка размерностей DataFrame'ов\n",
    "for name, dataframe in zip(['job_X_train', 'job_X_test', 'job_y_test'],\n",
    "                           [job_X_train, job_X_test, job_y_test]):\n",
    "    print(f\"Размер {name}: {dataframe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тренеровочные данные\n",
    "## Создали скопировали датасет job_X_train и опрелели индекс\n",
    "job_X_train_ml = job_X_train.copy().set_index('id')\n",
    "\n",
    "## Выдели целевой признак job_satisfaction_rate из job_X_train_ml\n",
    "job_y_train_ml = job_X_train_ml['job_satisfaction_rate']\n",
    "\n",
    "##Удалим целевой принак из тренеровояной базы\n",
    "job_X_train_ml = job_X_train_ml.drop('job_satisfaction_rate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверка размерности\n",
    "job_X_train_ml.shape[0]-job_y_train_ml.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Тестовые данные\n",
    "job_X_test_ml = job_X_test.set_index('id')\n",
    "job_y_test_ml = job_y_test.set_index('id')\n",
    "job_full_test = job_X_test_ml.merge(job_y_test_ml, on='id', how='left')\n",
    "\n",
    "## Выдели целевой признак job_satisfaction_rate\n",
    "job_y_test_ml = job_full_test['job_satisfaction_rate']\n",
    "\n",
    "##Удалим целевой принак из тестовой базы\n",
    "job_X_test_ml = job_full_test.drop('job_satisfaction_rate', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим размерность\n",
    "# Оптимизированная проверка размерностей DataFrame'ов\n",
    "for name, dataframe in zip(['job_X_train_ml', 'job_y_train_ml', 'job_X_test_ml','job_y_test_ml'],\n",
    "                           [job_X_train_ml, job_y_train_ml, job_X_test_ml,job_y_test_ml]):\n",
    "    print(f\"Размер {name}: {dataframe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Количество дубликатов job_X_train_ml после корректировок:', job_X_train_ml.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Убирем дубликаты из job_X_train_ml\n",
    "job_X_train_ml.drop_duplicates(inplace=True, ignore_index=False)\n",
    "\n",
    "#Синхронизируем job_y_train_ml с job_X_train_ml по индексу после удаления дубликато\n",
    "job_y_train_ml = job_y_train_ml[job_y_train_ml.index.isin(job_X_train_ml.index)]\n",
    "\n",
    "\n",
    "display('Количество дубликатов job_X_train_ml после корректировок:', job_X_train_ml.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим размерность\n",
    "# Оптимизированная проверка размерностей DataFrame'ов\n",
    "for name, dataframe in zip(['job_X_train_ml', 'job_y_train_ml', 'job_X_test_ml','job_y_test_ml'],\n",
    "                           [job_X_train_ml, job_y_train_ml, job_X_test_ml,job_y_test_ml]):\n",
    "    print(f\"Размер {name}: {dataframe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1.5. Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Строим пайплан"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Создаём списки с названиями признаков\n",
    "ohe_columns = ['dept', 'last_year_promo', 'last_year_violations']\n",
    "ord_columns = ['level', 'workload']\n",
    "num_columns = ['employment_years', 'supervisor_evaluation', 'salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Заполнение пропусков SimpleImputer и OHE-кодирование\n",
    "ohe_pipe = Pipeline(\n",
    "    [\n",
    "        # Шаг 1: Заполнение пропусков наиболее часто встречающимся значением\n",
    "        (\n",
    "            'simpleImputer_ohe',  # Название шага\n",
    "            SimpleImputer(missing_values=np.nan, strategy='most_frequent')  # Заполнение пропусков\n",
    "        ),\n",
    "        # Шаг 2: OneHotEncoder для кодирования категориальных признаков\n",
    "        (\n",
    "            'ohe',  # Название шага\n",
    "            OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')  # One-hot кодирование\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "ohe_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Заполнение пропусков SimpleImputer и Ordinal-кодирование (OE)\n",
    "ord_pipe = Pipeline(\n",
    "    [\n",
    "        # Шаг 1: Замена пропущенных значений на наиболее часто встречающееся значение\n",
    "        (\n",
    "            'simpleImputer_before_ord',  # Название шага\n",
    "            SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "        ),\n",
    "        # Шаг 2: Кодирование категориальных признаков порядковыми значениями\n",
    "        (\n",
    "            'ord',  # Название шага\n",
    "            OrdinalEncoder(\n",
    "                categories=[['junior', 'middle', 'senior'], ['low', 'medium', 'high']],  # Категории для кодирования\n",
    "                #handle_unknown='use_encoded_value', unknown_value=-1  # Используем -1 для неизвестных категорий\n",
    "                handle_unknown='use_encoded_value', unknown_value=np.nan\n",
    "            )\n",
    "        ),\n",
    "        # Шаг 3: Замена пропущенных значений на наиболее часто встречающееся значение после кодирования\n",
    "        (\n",
    "            'simpleImputer_after_ord',  # Название шага\n",
    "            SimpleImputer(missing_values=-1, strategy='most_frequent')  # Заполняем пропуски, которые были закодированы как -1\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "ord_pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Объединим кодирование и масштабирование в один пайплайн с подготовкой данных data_preprocessor\n",
    "data_preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        # Шаг 1: Применяем one-hot encoding для выбранных категориальных столбцов\n",
    "        ('ohe', ohe_pipe, ohe_columns),  # Применяем ohe_pipe к ohe_columns\n",
    "        # Шаг 2: Применяем порядковое кодирование для выбранных категориальных столбцов\n",
    "        ('ord', ord_pipe, ord_columns),  # Применяем ord_pipe к ord_columns\n",
    "        # Шаг 3: Применяем MinMaxScaler для числовых столбцов\n",
    "        ('num', MinMaxScaler(), num_columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Пропускаем остальные столбцы без изменений\n",
    ")\n",
    "data_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Создаем итоговый пайплан. Базовая модель - DecisionTreeClassifier\n",
    "pipe_final = Pipeline([\n",
    "    ('preprocessor', data_preprocessor),\n",
    "    ('models', DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "pipe_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Создаем переменную `param_grid` для регрессионной задачи\n",
    "#  — это набор возможных моделей и гиперпараметров для каждой модели\n",
    "#Проверь актуализируй параметр X_train в 'select_kbest__k'\n",
    "# Обновляем param_grid для поиска оптимального количества признаков (k)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'models': [KNeighborsRegressor()],\n",
    "        'models__n_neighbors': range(2, 10),\n",
    "        'preprocessor__num': [StandardScaler(), MinMaxScaler(), RobustScaler(), 'passthrough'],\n",
    "   },\n",
    "    {\n",
    "        'models': [DecisionTreeRegressor(random_state=RANDOM_STATE)],\n",
    "        'models__max_depth': range(2, 10),\n",
    "        'models__max_features': range(2, 10),\n",
    "        'preprocessor__num': [StandardScaler(), MinMaxScaler(), RobustScaler(), 'passthrough'],\n",
    "        \n",
    "    },\n",
    "   \n",
    "    {\n",
    "        'models': [LGBMRegressor(random_state=RANDOM_STATE, n_jobs=-1, verbose=-1)],\n",
    "        'models__max_depth': range(1, 50),\n",
    "        'models__n_estimators': range(10, 100),\n",
    "        'preprocessor__num': [StandardScaler(), MinMaxScaler(), 'passthrough'],\n",
    "        \n",
    "    }\n",
    "\n",
    "   ]\n",
    "\n",
    "param_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Создаём списки с названиями признаков\n",
    "ohe_columns = ['dept', 'last_year_promo', 'last_year_violations']\n",
    "ord_columns = ['level', 'workload']\n",
    "num_columns = ['employment_years', 'supervisor_evaluation', 'salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Создаем функцию для расчета новой метрики\n",
    "\"\"\"\"\n",
    "SMAPE (англ. symmetric mean absolute percentage error, «симметричное среднее абсолютное процентное отклонение»). \n",
    "Метрика SMAPE вычисляется так:\n",
    "`SMAPE=100𝑛∑𝑖=1𝑛∣𝑦𝑖−𝑦𝑖^∣(∣𝑦𝑖∣+∣𝑦^𝑖∣)/2,SMAPE=n100∑i=1n(∣yi∣+∣y^i∣)/2∣yi−yi^∣`\n",
    "где:\n",
    "* 𝑦𝑖yi — фактическое значение целевого признака для объекта с порядковым номером 𝑖i в выборке;\n",
    "* 𝑦𝑖^yi^ — предсказанное значение целевого признака для объекта с порядковым номером 𝑖i в выборке;\n",
    "* 𝑛n — количество объектов в выборке;\n",
    "* ∑𝑖=1𝑛∑i=1n — сумма значений, полученная в результате операций, которые следуют за этим знаком, для всех объектов с порядковым номером от 𝑖i до 𝑛n в выборке.\n",
    "\"\"\"\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Функция принимает на вход массивы NumPy или объекты Series в pandas и возвращает значение метрики SMAPE\n",
    "    (симметричное среднее абсолютное процентное отклонение)\n",
    "\n",
    "    Args:\n",
    "        y_true(np.array / pandas.Series): Массив с фактическими значениями данных\n",
    "        y_pred(np.array / pandas.Series): Массив с прогнозируемыми значениями данных \n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    diff = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator != 0)\n",
    "    return np.mean(diff) * 100\n",
    "\n",
    "\n",
    "# Создаём пользовательскую метрику\n",
    "smape_score = make_scorer(smape, greater_is_better=False)\n",
    "smape_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор гиперпараметров для пайплайна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем рекомендованную метрику, которая была расчитана ранее `smape_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = RandomizedSearchCV(\n",
    "    pipe_final,\n",
    "    param_grid,\n",
    "    n_jobs=-1,\n",
    "    n_iter=100,\n",
    "    cv=10,\n",
    "    scoring=smape_score,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(job_X_train_ml, job_y_train_ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Лучшая модель и её параметры:\\n\\n', grid_search.best_estimator_)\n",
    "print(line_1)\n",
    "print('Параметры лучшей модели:', grid_search.best_params_)\n",
    "print(line_1)\n",
    "print('Метрика лучшей модели по кросс-валидации на обучающих данных:', grid_search.best_score_*-1)\n",
    "print(line_1)\n",
    "job_y_test_pred = grid_search.best_estimator_.predict(job_X_test_ml)\n",
    "print(f'SMAPE на тестовой выборке: {smape(job_y_test_ml, job_y_test_pred)}')\n",
    "print(line_1)\n",
    "print(line_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ важности признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем лучшую модель и пайплайн предобработки данных из grid_search\n",
    "# model - сама модель, preprocessor_pipe - пайплайн предобработки данных (например, масштабирование, кодирование признаков)\n",
    "model = grid_search.best_estimator_.named_steps['models']\n",
    "preprocessor_pipe = grid_search.best_estimator_.named_steps['preprocessor']\n",
    "\n",
    "# Масштабируем и обрабатываем тестовые данные с помощью пайплайна\n",
    "# Это те же шаги предобработки, которые применялись к тренировочным данным\n",
    "X_test_scaled = preprocessor_pipe.transform(job_X_test_ml)\n",
    "\n",
    "# Получаем названия признаков после предобработки (если были категории, они могли стать OHE-признаками)\n",
    "feature_names = preprocessor_pipe.get_feature_names_out()\n",
    "\n",
    "# Создаем объяснитель для модели с помощью SHAP\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Получаем SHAP-значения для тестовых данных\n",
    "# SHAP-значения показывают вклад каждого признака в предсказания модели\n",
    "shap_values = explainer.shap_values(X_test_scaled)\n",
    "\n",
    "# Визуализируем важность признаков с использованием SHAP-значений\n",
    "# plot_type=\"bar\" создаёт гистограмму, показывающую суммарную важность каждого признака\n",
    "# show=False позволяет сначала внести изменения в график перед его отображением\n",
    "shap.summary_plot(shap_values, X_test_scaled, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "\n",
    "# Добавляем заголовок и подписи осей с помощью matplotlib\n",
    "# Ось X показывает суммарные SHAP-значения (влияние признаков)\n",
    "# Ось Y показывает сами признаки, отсортированные по важности\n",
    "plt.title(\"Суммарная важность каждого признака\")\n",
    "plt.xlabel(\"Суммарное вляние признака (SHAP)\")  # Подпись оси X\n",
    "plt.ylabel(\"Признаки\")  # Подпись оси Y\n",
    "\n",
    "# Отображаем график с добавленными подписями\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.named_steps['models']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "Основной вклад в предсказания модели вносят:\n",
    "- **`num__supervisor_evaluation`** (оценка от руководителя) — самый влиятельный признак.\n",
    "- **`num__employment_years`** (стаж работы в компании) и **`num__salary`** (зарплата) — также важны.\n",
    "- **`ohe__last_year_violations_yes`** (наличие нарушений) и **`ord__level`** (уровень должности) оказывают умеренное влияние.\n",
    "- Признаки, связанные с отделом (**`ohe__dept_*`**), имеют наименьшее влияние.\n",
    "\n",
    "Модель опирается в основном на производственные и финансовые показатели сотрудников."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1.6. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Промежуточные выводы о выбранной модели: \n",
    "- Ввели новую метрику — **SMAPE** (симметричное среднее абсолютное процентное отклонение).\n",
    "- Построили пайплайн;\n",
    "- Провели подбор гиперпараметров для трех моделей *KNeighborsRegressor*,*DecisionTreeRegressor* и *LGBMRegressor*, \n",
    "- Наилучшие результаты показала модель `LGBMRegressor(max_depth=19, n_estimators=77, random_state=42)`, с **SMAPE** на тестовых данных равным `11.298824391526017`.\n",
    "- Далее мы более тщательно настроили гиперпараметры для `LGBMRegressor`:\n",
    "- Лучшая модель оказалась с параметрами `LGBMRegressor(max_depth=34, n_estimators=99, n_jobs=-1, random_state=42,verbose=-1)`\n",
    "- Значение **SMAPE** на тестовой выборке составило **`11.04926727441189`**.\n",
    "\n",
    "\n",
    "- *LGBM, будучи градиентным бустингом на основе деревьев решений, способен моделировать сложные нелинейные взаимосвязи в данных*. Модель формирует ансамбль деревьев, каждое из которых улучшает результаты предыдущего, что помогает точнее предсказывать сложные зависимости. Поскольку на этапе анализа корреляций были выявлены нелинейные зависимости, LGBM оказался более подходящим для задачи, чем линейные модели. В целом, LGBM автоматически учитывает взаимодействия между признаками, что позволяет лучше адаптироваться к нелинейностям в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 2: предсказание увольнения сотрудника из компании"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2.1. Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем датасеты для второй задачи\n",
    "try:\n",
    "    quit_X_train = pd.read_csv('datasets/train_quit.csv')\n",
    "    quit_y_test = pd.read_csv('datasets/test_target_quit.csv')\n",
    "\n",
    "except:\n",
    "    quit_X_train = pd.read_csv('https://code.s3.yandex.net/datasets/train_quit.csv')\n",
    "    quit_y_test = pd.read_csv('https://code.s3.yandex.net/datasets/test_target_quit.csv')\n",
    "\n",
    "# Копируем тестовую выборку    \n",
    "quit_X_test = job_X_test_ml.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Общая информация о датасетах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `quit_X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info(quit_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `quit_y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info(quit_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по датасетам:\n",
    "\n",
    "1. **Датасет `quit_X_train` (тренировочная выборка)**:\n",
    "\n",
    "- **Размер**: 4000 записей и 10 столбцов.\n",
    "- **Признаки**:\n",
    "  - **id**: Уникальный идентификатор сотрудника (числовой).\n",
    "  - **dept**: Отдел, в котором работает сотрудник (категориальный).\n",
    "  - **level**: Уровень должности (категориальный).\n",
    "  - **workload**: Уровень загруженности (категориальный).\n",
    "  - **employment_years**: Количество лет работы в компании (целочисленный).\n",
    "  - **last_year_promo**: Было ли повышение за последний год (категориальный).\n",
    "  - **last_year_violations**: Были ли нарушения за последний год (категориальный).\n",
    "  - **supervisor_evaluation**: Оценка работы сотрудника от руководителя (целочисленный, от 1 до 5).\n",
    "  - **salary**: Зарплата сотрудника (целочисленный).\n",
    "  - **quit**: Целевой признак — увольнение (категориальный).\n",
    "\n",
    "- **Статистическое описание числовых признаков**:\n",
    "  - **employment_years**: Средний стаж работы составляет 3.7 года. Минимальное значение — 1 год, максимальное — 10 лет.\n",
    "  - **supervisor_evaluation**: Средняя оценка от руководителя — 3.47. Оценки варьируются от 1 до 5.\n",
    "  - **salary**: Средняя зарплата — 33,805 единиц, с минимальной зарплатой в 12,000 и максимальной в 96,000 единиц.\n",
    "\n",
    "- **Пропуски**: Пропущенных данных нет — все столбцы полностью заполнены.\n",
    "- **Дубликаты**: Явных дубликатов не обнаружено.\n",
    "\n",
    "2. **Датасет `quit_y_test` (тестовая выборка)**:\n",
    "\n",
    "- **Размер**: 2000 записей и 2 столбца.\n",
    "- **Признаки**:\n",
    "  - **id**: Уникальный идентификатор сотрудника (числовой).\n",
    "  - **quit**: Целевой признак — увольнение (категориальный).\n",
    "\n",
    "- **Пропуски**: Пропущенных данных нет — все столбцы полностью заполнены.\n",
    "\n",
    "**Общий вывод:**\n",
    "- Данные чистые: отсутствуют пропуски и дубликаты.\n",
    "- В тренировочной выборке представлены как числовые (стаж работы, зарплата, оценка руководителя), так и категориальные признаки (отдел, уровень должности, загруженность и т.д.).\n",
    "- Средний стаж сотрудников составляет около 3.7 лет, с зарплатой около 33,805 единиц.\n",
    "- Признак **quit** является целевым, и его задача — предсказать, уволится сотрудник или нет.\n",
    "\n",
    "Можно приступить к дальнейшему анализу данных или построению модели для предсказания увольнений сотрудников."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2.2. Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `quit_X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выявление неявных дубликатов. Создадим словарь с уникальными значениями для каждого категориального признака\n",
    "unique_values_dict_1 = {col: quit_X_train[col].unique().tolist() for col in quit_X_train.columns if quit_X_train[col].dtype == 'object'}\n",
    "unique_values_dict_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка и исправление опечаток**: Необходимо исправить опечатку `'sinior'` на `'senior'` в признаке `level`, чтобы избежать появления новых категорий и ошибок при обучении модели.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Повторное исправление опечатки в колонке level\n",
    "quit_X_train['level'] = quit_X_train['level'].replace('sinior', 'senior')\n",
    "\n",
    "# Проверим уникальные значения в колонке 'level' после исправления\n",
    "quit_X_train['level'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `quit_y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit_y_test.info()\n",
    "quit_y_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit_y_test['quit'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `quit_X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit_X_test.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit_X_test = job_X_test_ml.merge(quit_y_test, on='id', how='inner')\n",
    "quit_X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодируем таргет через LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit([\"no\", \"yes\"])\n",
    "quit_X_train['quit'] = le.transform(quit_X_train['quit'])\n",
    "quit_X_test['quit'] = le.transform(quit_X_test['quit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit_X_train.info()\n",
    "quit_X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit_X_test.info()\n",
    "quit_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Грамотно индексируем выборки\n",
    "quit_X_train = quit_X_train.set_index('id')\n",
    "quit_X_test = quit_X_test.set_index('id')\n",
    "\n",
    "display(quit_X_train.head(1))\n",
    "display(quit_X_test.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2.3. Исследовательский анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Количественные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Гистограммы\n",
    "plot_histograms_for_df(quit_X_train,'Данные', quit_discrete_columns, quit_continuous_columns)\n",
    "\n",
    "#Выбросы\n",
    "plot_interactive_plots(quit_X_train,'Данные', quit_discrete_columns, quit_continuous_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Категориальные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_features(quit_X_train,'Данные', quit_categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корреляционный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_correlation_analysis(quit_X_train, quit_discrete_columns, quit_continuous_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы EDA\n",
    "\n",
    "1. **employment_years** (стаж работы):\n",
    "   - Большинство сотрудников работают 1-3 года. Стаж свыше 6 лет встречается реже.\n",
    "   - Стаж положительно коррелирует с **salary** (зарплатой) и **supervisor_evaluation** (оценкой руководителя).\n",
    "\n",
    "2. **supervisor_evaluation** (оценка руководителя):\n",
    "   - Основная часть сотрудников имеет высокие оценки (3-4), что свидетельствует о хорошей производительности.\n",
    "   - Низкие оценки сотрудников могут быть связаны с повышенной вероятностью увольнения.\n",
    "\n",
    "3. **salary** (зарплата):\n",
    "   - Зарплаты варьируются от 12,000 до 96,000. Средняя зарплата составляет 33,805, медиана — 30,000.\n",
    "   - Более высокая зарплата связана с меньшей вероятностью увольнения (**quit**).\n",
    "\n",
    "4. **dept** (отдел):\n",
    "   - Большинство сотрудников работают в отделах **sales** (35.9%) и **technology** (23.2%).\n",
    "   - Отдел **hr** представлен наименьшей долей сотрудников (11.6%).\n",
    "\n",
    "5. **last_year_violations** и **last_year_promo** (нарушения и повышения за последний год):\n",
    "   - 86.4% сотрудников не имеют нарушений трудовой дисциплины.\n",
    "   - Только 2.8% сотрудников были повышены за последний год, что указывает на низкую частоту карьерных изменений.\n",
    "\n",
    "6. **Корреляция признаков**:\n",
    "   - **salary** (зарплата) и **employment_years** (стаж работы) имеют положительную корреляцию с **quit** (увольнением).\n",
    "   - Значимая корреляция также наблюдается между **level** (уровень должности), **workload** (загруженность) и **salary** (зарплата).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описание портрета уволившихся\n",
    "plot_quit_analysis_in_columns(quit_X_train, target='quit', plot_type='box', cols=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T10:37:51.786025Z",
     "iopub.status.busy": "2024-10-13T10:37:51.785033Z",
     "iopub.status.idle": "2024-10-13T10:37:51.795279Z",
     "shell.execute_reply": "2024-10-13T10:37:51.795279Z",
     "shell.execute_reply.started": "2024-10-13T10:37:51.786025Z"
    }
   },
   "source": [
    "**Анализ каждого графика:**\n",
    "\n",
    "1. **`employment_years` по `dept` с учётом `quit`**:\n",
    "   - Уволившиеся сотрудники имеют меньший стаж работы (в среднем 1-3 года) во всех отделах, особенно в отделах **sales** и **purchasing**.\n",
    "   - В отделе **technology** сотрудники остаются работать дольше, но всё равно увольняются с меньшим стажем.\n",
    "\n",
    "2. **`supervisor_evaluation` по `dept` с учётом `quit`**:\n",
    "   - В целом, оценки от руководителей практически не отличаются для уволившихся и оставшихся сотрудников во всех отделах, за исключением отдела **hr**, где оценки у уволившихся ниже.\n",
    "   - Это может указывать на то, что оценка от руководителя не является главным фактором увольнения.\n",
    "\n",
    "3. **`salary` по `dept` с учётом `quit`**:\n",
    "   - Уволившиеся сотрудники получают значительно меньшие зарплаты по сравнению с оставшимися, особенно в отделах **technology** и **marketing**.\n",
    "   - В отделах **sales** и **purchasing** также наблюдается заметное снижение зарплат среди уволившихся.\n",
    "\n",
    "4. **`employment_years` по `level` с учётом `quit`**:\n",
    "   - Уволившиеся сотрудники на уровне **junior** имеют минимальный стаж (1-2 года), в то время как сотрудники уровня **middle** и **senior** остаются в компании дольше.\n",
    "   - Вероятно, сотрудники уровня **junior** увольняются на ранних этапах карьеры из-за недостаточной удовлетворённости работой или недостатка карьерного роста.\n",
    "\n",
    "5. **`supervisor_evaluation` по `level` с учётом `quit`**:\n",
    "   - Разница в оценках от руководителя между уволившимися и оставшимися сотрудниками минимальна, что подтверждает предыдущий вывод о незначительном влиянии этого признака на увольнение.\n",
    "   - На уровне **junior** оценки руководителей остаются одинаковыми для обеих групп.\n",
    "\n",
    "6. **`salary` по `level` с учётом `quit`**:\n",
    "   - Уволившиеся сотрудники на уровне **junior** получают на 10 000–15 000 меньше, чем оставшиеся. Разница особенно заметна на уровнях **junior** и **middle**.\n",
    "   - Это указывает на то, что сотрудники с низким уровнем дохода более склонны к увольнению, особенно на низших уровнях.\n",
    "\n",
    "7. **`employment_years` по `workload` с учётом `quit`**:\n",
    "   - Уволившиеся сотрудники имеют меньший стаж на всех уровнях загруженности (**low**, **medium**, **high**), особенно на низком уровне загруженности.\n",
    "   - Возможно, сотрудники с низкой загруженностью менее мотивированы или менее привязаны к работе.\n",
    "\n",
    "8. **`salary` по `workload` с учётом `quit`**:\n",
    "   - Зарплаты уволившихся сотрудников заметно ниже по всем уровням загруженности. Особенно заметна разница среди сотрудников с низкой загруженностью (**low**).\n",
    "   - Сотрудники с высокой загруженностью и низкой зарплатой также чаще увольняются.\n",
    "\n",
    "9. **`employment_years` по `last_year_promo` с учётом `quit`**:\n",
    "   - Большинство уволившихся сотрудников не получали повышения за последний год, что может быть одной из причин увольнения.\n",
    "   - Стаж уволившихся сотрудников, которые не получали повышения, значительно ниже.\n",
    "\n",
    "10. **`supervisor_evaluation` по `last_year_promo` с учётом `quit`**:\n",
    "   - Оценка от руководителя не оказывает значительного влияния на увольнение, как и в предыдущих графиках. Независимо от наличия повышения, оценки остаются стабильными.\n",
    "\n",
    "11. **`salary` по `last_year_promo` с учётом `quit`**:\n",
    "   - Зарплата уволившихся сотрудников, не получивших повышения, значительно ниже, чем у оставшихся.\n",
    "   - Сотрудники, получившие повышение, имеют более высокие зарплаты, но среди них уволившихся немного.\n",
    "\n",
    "12. **`employment_years` по `last_year_violations` с учётом `quit`**:\n",
    "   - Сотрудники, совершившие нарушения за последний год, чаще увольняются, особенно с меньшим стажем работы.\n",
    "   - Стаж работы у оставшихся сотрудников без нарушений выше.\n",
    "\n",
    "13. **`supervisor_evaluation` по `last_year_violations` с учётом `quit`**:\n",
    "   - Сотрудники с нарушениями получают более низкие оценки от руководителей, особенно среди уволившихся.\n",
    "\n",
    "14. **`salary` по `last_year_violations` с учётом `quit`**:\n",
    "   - Уволившиеся сотрудники с нарушениями за последний год получают заметно более низкие зарплаты, что может быть связано с дисциплинарными мерами или общим уровнем удовлетворённости.\n",
    "\n",
    "---\n",
    "\n",
    "**Общий портрет уволившихся сотрудников:**\n",
    "\n",
    "1. **Зарплата**:\n",
    "   - Основным фактором, связанным с увольнением, является низкий уровень зарплаты. Во всех отделах, на всех уровнях должностей и загруженности, уволившиеся сотрудники зарабатывают значительно меньше, чем оставшиеся.\n",
    "\n",
    "2. **Стаж работы**:\n",
    "   - Сотрудники с небольшим стажем (1–3 года) гораздо чаще увольняются. Это особенно заметно на уровнях **junior** и среди сотрудников с низкой загруженностью.\n",
    "\n",
    "3. **Уровень должности**:\n",
    "   - Сотрудники уровня **junior** значительно чаще увольняются, особенно если они получают низкие оценки от руководства и зарплату ниже среднего.\n",
    "\n",
    "4. **Загруженность**:\n",
    "   - Сотрудники с низкой загруженностью также чаще увольняются, особенно если их зарплата не соответствует ожиданиям.\n",
    "\n",
    "5. **Нарушения и повышение**:\n",
    "   - Сотрудники, которые совершили нарушения трудовой дисциплины за последний год, а также те, кто не получил повышения, чаще увольняются, особенно если они получают более низкие зарплаты и имеют небольшой стаж.\n",
    "\n",
    "Этот анализ помогает выделить ключевые факторы, влияющие на увольнение, и может быть полезен для улучшения условий труда и удержания сотрудников в компании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2.4. Добавление нового входного признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, job_satisfaction_rate и quit действительно связаны и вы получили необходимое значение метрики в первой задаче. Тогда добавьте job_satisfaction_rate, предсказанный лучшей моделью первой задачи, к входным признакам второй задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Тренеровочные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим совпадение ID работников в обучающих датасетах\n",
    "common_ids = set(quit_X_train.index).intersection(set(job_X_train.index))\n",
    "print(\"Общие 'id':\", len(common_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: не совподают. Спргнозируем job_satisfaction_rate для тренеровочных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Спрогнозируем job_satisfaction_rate для quit_X_train\n",
    "quit_train_J = grid_search.best_estimator_.predict(quit_X_train)\n",
    "quit_train_J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подготовим данные\n",
    "quit_X_train_ml = quit_X_train.copy(deep=True)\n",
    "quit_X_train_ml['job_satisfaction_rate'] = quit_train_J\n",
    "quit_X_train_ml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тестовые данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим job_satisfaction_rate значение предсказанного целевого признака первой модели job_y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим, количество схожих ID работников в тестовых датасетах\n",
    "common_ids = set(quit_X_test.index).intersection(set(job_X_test_ml.index))\n",
    "print(len(quit_X_test))\n",
    "print(len(job_X_test_ml))\n",
    "print(\"Общие 'id':\", len(common_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индексы совподают. Загрузим данные в job_satisfaction_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit_X_test_ml = quit_X_test.copy(deep=True)\n",
    "quit_X_test_ml['job_satisfaction_rate'] = job_y_test_pred\n",
    "quit_X_test_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим размерность\n",
    "# Оптимизированная проверка размерностей DataFrame'ов\n",
    "for name, dataframe in zip(['quit_X_train_ml', 'quit_X_test_ml'],\n",
    "                           [quit_X_train_ml, quit_X_test_ml]):\n",
    "    print(f\"Размер {name}: {dataframe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2.5. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем целевой признак и убираем в тренировочной выборке\n",
    "quit_y_train_ml = quit_X_train_ml['quit']\n",
    "quit_X_train_ml = quit_X_train_ml.drop('quit', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем целевой признак и убираем в тестовой выборке\n",
    "quit_y_test_ml = quit_X_test['quit']\n",
    "quit_X_test_ml = quit_X_test_ml.drop('quit', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим размерность\n",
    "# Оптимизированная проверка размерностей DataFrame'ов\n",
    "for name, dataframe in zip(['quit_X_train_ml', 'quit_y_train_ml', 'quit_X_test_ml','quit_y_test_ml'],\n",
    "                           [quit_X_train_ml, quit_y_train_ml, quit_X_test_ml,quit_y_test_ml]):\n",
    "    print(f\"Размер {name}: {dataframe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display('Количество дубликатов quit_X_train_ml после корректировок:', quit_X_train_ml.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удаляем дубликаты\n",
    "quit_X_train_ml.drop_duplicates(inplace=True, ignore_index=False)\n",
    "# Проверка\n",
    "display('Количество дубликатов quit_X_train_ml после удаления:', quit_X_train_ml.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Отфильтруем в quit_y_train_ml строки так, чтобы остались только\n",
    "#  те строки, которые имеют соответствующие признаки в quit_X_train_ml\n",
    "\n",
    "quit_y_train_ml = quit_y_train_ml[quit_y_train_ml.index.isin(quit_X_train_ml.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим размерность\n",
    "# Оптимизированная проверка размерностей DataFrame'ов\n",
    "for name, dataframe in zip(['quit_X_train_ml', 'quit_y_train_ml', 'quit_X_test_ml','quit_y_test_ml'],\n",
    "                           [quit_X_train_ml, quit_y_train_ml, quit_X_test_ml,quit_y_test_ml]):\n",
    "    print(f\"Размер {name}: {dataframe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Настройка пайпа с учетом того, что добавили новый признак в выборки - job_satisfaction_rate\n",
    "## 1. В числовые данные  num_columns добавляем job_satisfaction_rate\n",
    "num_columns.append('job_satisfaction_rate')\n",
    "\n",
    "## 2. После добавления нового признака важно обновить пайплайн, \n",
    "# чтобы этот признак корректно обрабатывался и использовался моделью \n",
    "# LogisticRegression для предсказаний.\n",
    "\n",
    "pipe_final_1 = Pipeline([\n",
    "    ('preprocessor', data_preprocessor),\n",
    "    ('models', LogisticRegression(random_state=RANDOM_STATE))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2.6. Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор гиперпараметров для пайплайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_1 = [\n",
    "    {\n",
    "        'models': [KNeighborsClassifier()],\n",
    "        'models__n_neighbors': range(2, 5),\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        'models': [DecisionTreeClassifier(random_state=RANDOM_STATE)],\n",
    "        'models__max_depth': range(2, 5),\n",
    "        'models__max_features': range(2, 5),\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        'models': [LogisticRegression(random_state=RANDOM_STATE, solver='liblinear', penalty='l1')],\n",
    "        'models__C': range(1, 5),\n",
    "    },\n",
    "    {\n",
    "        'models': [LGBMClassifier(random_state=RANDOM_STATE, n_jobs=-1, verbose=-1)],\n",
    "        'models__max_depth': range(1, 21),\n",
    "        'models__n_estimators': range(80, 120),\n",
    "        \n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_search_1 = RandomizedSearchCV(\n",
    "    pipe_final_1,\n",
    "    param_grid_1,\n",
    "    n_jobs=-1,\n",
    "    n_iter=100,\n",
    "    cv=10,\n",
    "    scoring='roc_auc',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_search_1.fit(quit_X_train_ml, quit_y_train_ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Лучшая модель и её параметры:\\n\\n', grid_search_1.best_estimator_)\n",
    "print(line_1)\n",
    "print('Параметры лучшей модели:', grid_search_1.best_params_)\n",
    "print(line_1)\n",
    "print('Метрика ROC-AUC лучшей модели по кросс-валидации на обучающих данных:', grid_search_1.best_score_)\n",
    "print(line_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ важности признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем лучшую модель и пайплайн предобработки данных из grid_search\n",
    "# model - сама модель, preprocessor_pipe - пайплайн предобработки данных (например, масштабирование, кодирование признаков)\n",
    "model = grid_search_1.best_estimator_.named_steps['models']\n",
    "preprocessor_pipe = grid_search_1.best_estimator_.named_steps['preprocessor']\n",
    "\n",
    "# Масштабируем и обрабатываем тестовые данные с помощью пайплайна\n",
    "# Это те же шаги предобработки, которые применялись к тренировочным данным\n",
    "X_test_scaled = preprocessor_pipe.transform(quit_X_test_ml)\n",
    "\n",
    "# Получаем названия признаков после предобработки (если были категории, они могли стать OHE-признаками)\n",
    "feature_names = preprocessor_pipe.get_feature_names_out()\n",
    "\n",
    "# Создаем объяснитель для модели с помощью SHAP\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Получаем SHAP-значения для тестовых данных\n",
    "# SHAP-значения показывают вклад каждого признака в предсказания модели\n",
    "shap_values = explainer.shap_values(X_test_scaled)\n",
    "\n",
    "# Визуализируем важность признаков с использованием SHAP-значений\n",
    "# plot_type=\"bar\" создаёт гистограмму, показывающую суммарную важность каждого признака\n",
    "# show=False позволяет сначала внести изменения в график перед его отображением\n",
    "shap.summary_plot(shap_values, X_test_scaled, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "\n",
    "# Добавляем заголовок и подписи осей с помощью matplotlib\n",
    "# Ось X показывает суммарные SHAP-значения (влияние признаков)\n",
    "# Ось Y показывает сами признаки, отсортированные по важности\n",
    "plt.title(\"Суммарная важность каждого признака\")\n",
    "plt.xlabel(\"Суммарное вляние признака (SHAP)\")  # Подпись оси X\n",
    "plt.ylabel(\"Признаки\")  # Подпись оси Y\n",
    "\n",
    "# Отображаем график с добавленными подписями\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_1.best_estimator_.named_steps['models']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2.7. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основные факторы, влияющие на предсказание увольнений:**\n",
    "- **Стаж работы** (ключевой фактор).\n",
    "- **Уровень должности** и **удовлетворенность** работой также важны.\n",
    "- **Зарплата** имеет умеренное влияние.\n",
    "- **Отдел** и **нарушения** оказывают минимальное влияние на предсказания модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Задача 1: Предсказание уровня удовлетворенности сотрудника**:\n",
    "    - Ввели новую метрику — **SMAPE** (симметричное среднее абсолютное процентное отклонение).\n",
    "    - Построили пайплайн;\n",
    "    - Провели подбор гиперпараметров для трех моделей *KNeighborsRegressor*,*DecisionTreeRegressor* и *LGBMRegressor*, \n",
    "    - Наилучшие результаты показала модель `LGBMRegressor(max_depth=19, n_estimators=77, random_state=42)`, с **SMAPE** на тестовых данных равным `11.298824391526017`.\n",
    "    - Лучшая модель оказалась с параметрами `LGBMRegressor(max_depth=34, n_estimators=99, n_jobs=-1, random_state=42,verbose=-1)`\n",
    "    - Значение **SMAPE** на тестовой выборке составило **`11.04926727441189`**.\n",
    "\n",
    "2. **Задача 2: Предсказание увольнения**:\n",
    "   - Лучшая модель: **`LGBMRegressor(max_depth=2, n_estimators=96, n_jobs=-1, random_state=42, verbose=-1)`**.\n",
    "   - **ROC-AUC** на тестовой выборке: **0.93**.\n",
    "   - Важнейшие признаки: стаж работы и уровень должности.\n",
    "\n",
    "3. **Рекомендации**:\n",
    "   - Обращать внимание на оценку труда и удовлетворенность сотрудников.\n",
    "   - Увеличить удержание сотрудников через соц. программы и премии.\n",
    "   - Обратить внимание на условия работы в отделе продаж для снижения текучки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
